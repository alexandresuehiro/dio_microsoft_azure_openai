# -*- coding: utf-8 -*-
"""Untitled6.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1o3-4os8A-eAOXlNv4oY8uNg-0F2vdsRk
"""

! pip install requests python-docx

import requests
from docx import Document
import os
import json

subscription_key = "SUBSCRIPTION_KEY_HERE"
endpoint = 'https://api.cognitive.microsofttranslator.com'
location = 'LOCATION_REGION_HERE'
target_language = 'pt-br'
path = '/translate'

def translator_text(text, target_language):

  constructed_url = endpoint + path

  headers = {
      'Ocp-Apim-Subscription-Key': subscription_key,
      'Ocp-Apim-Subscription-Region': location,
      'Content-type': 'application/json',
      'X-ClientTraceId': str(os.urandom(16))
  }

  body = [{
      'text': text
  }]

  params = {
      'api-version': '3.0',
      'from': 'en',
      'to': target_language
  }

  request = requests.post(constructed_url, headers=headers, json=body, params=params)
  response = request.json()

  return response[0]["translations"][0]["text"]

translator_text("Hello there", target_language)

def translate_docx(input_file):
    doc = Document(input_file)
    full_text = []

    for paragraph in doc.paragraphs:
        translated_text = translator_text(paragraph.text, target_language)
        full_text.append(translated_text)

    translated_doc = Document()
    for line in translated_text:
        print(line)
        translated_doc.add_paragraph(line)
    path_translated_doc = input_file.replace(".docx", f"_{target_language}.docx")
    #translated_doc.add_paragraph('\n'.join(translated_text))
    translated_doc.save(path_translated_doc)


    return path_translated_doc

input_file = "/content/Better Together.docx"
translate_docx(input_file)


def extract_text_from_url(url):
    response = requests.get(url)

    if response.status_code == 200:
        soup = BeautifulSoup(response.text, 'html.parser')
        for script_or_style in soup(["script", "style"]):
            script_or_style.decompose()
        texto = soup.get_text(separator=' ')
        #Limpar texto
        lines = (line.strip() for line in texto.splitlines())
        chunks = (phrase.strip() for line in lines for phrase in line.split("  "))
        texto_limpo = '\n'.join(chunk for chunk in chunks if chunk)
        return texto_limpo
    else:
        print(f"Erro ao acessar a URL: {url}")
        return None

    return response.text

article = extract_text_from_url('https://www.letras.mus.br/jack-johnson/122710/')


from langchain_openai.chat_models.azure import AzureChatOpenAI

client = AzureChatOpenAI(
    azure_endpoint = 'ANOTHER_END_POINT_HERE',
    api_key="ANOTHER_KEY_HERE",
    api_version='2024-02-15-preview', #trying to use an older version
    deployment_name='gpt-4o-mini',
    max_retries=0
)

def translate_article(text, lang):
  messages = [
      ("system", "Voce atua como tradutor de textos"),
      ("user", f"Traduza o {text} para o idioma {lang} e responda em markdown")

  ]
  response = client.invoke(messages)
  print(response.content)
  return response.content


translated = translate_article(article, "pt-br")
print(translated)
